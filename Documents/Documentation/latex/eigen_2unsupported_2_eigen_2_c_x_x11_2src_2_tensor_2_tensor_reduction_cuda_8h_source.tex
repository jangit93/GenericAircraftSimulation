\hypertarget{eigen_2unsupported_2_eigen_2_c_x_x11_2src_2_tensor_2_tensor_reduction_cuda_8h_source}{}\section{eigen/unsupported/\+Eigen/\+C\+X\+X11/src/\+Tensor/\+Tensor\+Reduction\+Cuda.h}
\label{eigen_2unsupported_2_eigen_2_c_x_x11_2src_2_tensor_2_tensor_reduction_cuda_8h_source}\index{Tensor\+Reduction\+Cuda.\+h@{Tensor\+Reduction\+Cuda.\+h}}

\begin{DoxyCode}
00001 \textcolor{comment}{// This file is part of Eigen, a lightweight C++ template library}
00002 \textcolor{comment}{// for linear algebra.}
00003 \textcolor{comment}{//}
00004 \textcolor{comment}{// Copyright (C) 2014 Benoit Steiner <benoit.steiner.goog@gmail.com>}
00005 \textcolor{comment}{//}
00006 \textcolor{comment}{// This Source Code Form is subject to the terms of the Mozilla}
00007 \textcolor{comment}{// Public License v. 2.0. If a copy of the MPL was not distributed}
00008 \textcolor{comment}{// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.}
00009 
00010 \textcolor{preprocessor}{#ifndef EIGEN\_CXX11\_TENSOR\_TENSOR\_REDUCTION\_CUDA\_H}
00011 \textcolor{preprocessor}{#define EIGEN\_CXX11\_TENSOR\_TENSOR\_REDUCTION\_CUDA\_H}
00012 
00013 \textcolor{keyword}{namespace }\hyperlink{namespace_eigen}{Eigen} \{
00014 \textcolor{keyword}{namespace }\hyperlink{namespaceinternal}{internal} \{
00015 
00016 
00017 \textcolor{preprocessor}{#if defined(EIGEN\_USE\_GPU) && defined(\_\_CUDACC\_\_)}
00018 \textcolor{comment}{// Full reducers for GPU, don't vectorize for now}
00019 
00020 \textcolor{comment}{// Reducer function that enables multiple cuda thread to safely accumulate at the same}
00021 \textcolor{comment}{// output address. It basically reads the current value of the output variable, and}
00022 \textcolor{comment}{// attempts to update it with the new value. If in the meantime another cuda thread}
00023 \textcolor{comment}{// updated the content of the output address it will try again.}
00024 \textcolor{keyword}{template} <\textcolor{keyword}{typename} T, \textcolor{keyword}{typename} R>
00025 \_\_device\_\_ EIGEN\_ALWAYS\_INLINE \textcolor{keywordtype}{void} atomicReduce(\hyperlink{group___sparse_core___module_class_eigen_1_1_triplet}{T}* output, \hyperlink{group___sparse_core___module_class_eigen_1_1_triplet}{T} accum, R& reducer) \{
00026 \textcolor{preprocessor}{#if \_\_CUDA\_ARCH\_\_ >= 300}
00027   \textcolor{keywordflow}{if} (\textcolor{keyword}{sizeof}(\hyperlink{group___sparse_core___module_class_eigen_1_1_triplet}{T}) == 4)
00028   \{
00029     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} oldval = *\textcolor{keyword}{reinterpret\_cast<}\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}*\textcolor{keyword}{>}(output);
00030     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} newval = oldval;
00031     reducer.reduce(accum, reinterpret\_cast<T*>(&newval));
00032     \textcolor{keywordflow}{if} (newval == oldval) \{
00033       \textcolor{keywordflow}{return};
00034     \}
00035     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} readback;
00036     \textcolor{keywordflow}{while} ((readback = atomicCAS((\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}*)output, oldval, newval)) != oldval) \{
00037       oldval = readback;
00038       newval = oldval;
00039       reducer.reduce(accum, reinterpret\_cast<T*>(&newval));
00040       \textcolor{keywordflow}{if} (newval == oldval) \{
00041         \textcolor{keywordflow}{return};
00042       \}
00043     \}
00044   \}
00045   \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (\textcolor{keyword}{sizeof}(\hyperlink{group___sparse_core___module_class_eigen_1_1_triplet}{T}) == 8) \{
00046     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long} oldval = *\textcolor{keyword}{reinterpret\_cast<}\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long}*\textcolor{keyword}{>}(output);
00047     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long} newval = oldval;
00048     reducer.reduce(accum, reinterpret\_cast<T*>(&newval));
00049     \textcolor{keywordflow}{if} (newval == oldval) \{
00050       \textcolor{keywordflow}{return};
00051     \}
00052     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long} readback;
00053     \textcolor{keywordflow}{while} ((readback = atomicCAS((\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long}*)output, oldval, newval)) != oldval) \{
00054       oldval = readback;
00055       newval = oldval;
00056       reducer.reduce(accum, reinterpret\_cast<T*>(&newval));
00057       \textcolor{keywordflow}{if} (newval == oldval) \{
00058         \textcolor{keywordflow}{return};
00059       \}
00060     \}
00061   \}
00062   \textcolor{keywordflow}{else} \{
00063     assert(0 && \textcolor{stringliteral}{"Wordsize not supported"});
00064   \}
00065 \textcolor{preprocessor}{#else}
00066   assert(0 && \textcolor{stringliteral}{"Shouldn't be called on unsupported device"});
00067 \textcolor{preprocessor}{#endif}
00068 \}
00069 
00070 \textcolor{comment}{// We extend atomicExch to support extra data types}
00071 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Type>
00072 \_\_device\_\_ \textcolor{keyword}{inline} Type atomicExchCustom(Type* address, Type val) \{
00073   \textcolor{keywordflow}{return} atomicExch(address, val);
00074 \}
00075 
00076 \textcolor{keyword}{template} <>
00077 \_\_device\_\_ \textcolor{keyword}{inline} \textcolor{keywordtype}{double} atomicExchCustom(\textcolor{keywordtype}{double}* address, \textcolor{keywordtype}{double} val) \{
00078   \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long} \textcolor{keywordtype}{int}* address\_as\_ull = \textcolor{keyword}{reinterpret\_cast<}\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{long} \textcolor{keywordtype}{long} \textcolor{keywordtype}{int}*\textcolor{keyword}{>}(address);
00079   \textcolor{keywordflow}{return} \_\_longlong\_as\_double(atomicExch(address\_as\_ull, \_\_double\_as\_longlong(val)));
00080 \}
00081 
00082 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00083 \textcolor{keyword}{template} <\textcolor{keyword}{template} <\textcolor{keyword}{typename} T> \textcolor{keyword}{class }R>
00084 \_\_device\_\_ \textcolor{keyword}{inline} \textcolor{keywordtype}{void} atomicReduce(half2* output, half2 accum, R<half>& reducer) \{
00085   \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} oldval = *\textcolor{keyword}{reinterpret\_cast<}\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}*\textcolor{keyword}{>}(output);
00086   \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} newval = oldval;
00087   reducer.reducePacket(accum, reinterpret\_cast<half2*>(&newval));
00088   \textcolor{keywordflow}{if} (newval == oldval) \{
00089     \textcolor{keywordflow}{return};
00090   \}
00091   \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} readback;
00092   \textcolor{keywordflow}{while} ((readback = atomicCAS((\textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}*)output, oldval, newval)) != oldval) \{
00093     oldval = readback;
00094     newval = oldval;
00095     reducer.reducePacket(accum, reinterpret\_cast<half2*>(&newval));
00096     \textcolor{keywordflow}{if} (newval == oldval) \{
00097       \textcolor{keywordflow}{return};
00098     \}
00099   \}
00100 \}
00101 \textcolor{preprocessor}{#endif}
00102 
00103 \textcolor{keyword}{template} <>
00104 \_\_device\_\_ \textcolor{keyword}{inline} \textcolor{keywordtype}{void} atomicReduce(\textcolor{keywordtype}{float}* output, \textcolor{keywordtype}{float} accum, SumReducer<float>&) \{
00105 \textcolor{preprocessor}{#if \_\_CUDA\_ARCH\_\_ >= 300}
00106   atomicAdd(output, accum);
00107 \textcolor{preprocessor}{#else}
00108   assert(0 && \textcolor{stringliteral}{"Shouldn't be called on unsupported device"});
00109 \textcolor{preprocessor}{#endif}
00110 \}
00111 
00112 
00113 \textcolor{keyword}{template} <\textcolor{keyword}{typename} CoeffType, \textcolor{keyword}{typename} Index>
00114 \_\_global\_\_ \textcolor{keywordtype}{void} ReductionInitKernel(\textcolor{keyword}{const} CoeffType val, \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_preserved\_coeffs, CoeffType* output
      ) \{
00115   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} thread\_id = blockIdx.x * blockDim.x + threadIdx.x;
00116   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_threads = blockDim.x * gridDim.x;
00117   \textcolor{keywordflow}{for} (\hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} i = thread\_id; i < num\_preserved\_coeffs; i += num\_threads) \{
00118     output[i] = val;
00119   \}
00120 \}
00121 
00122 
00123 \textcolor{keyword}{template} <\textcolor{keywordtype}{int} BlockSize, \textcolor{keywordtype}{int} NumPerThread, \textcolor{keyword}{typename} Self,
00124           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index}>
00125 \_\_global\_\_ \textcolor{keywordtype}{void} FullReductionKernel(Reducer reducer, \textcolor{keyword}{const} Self input, \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_coeffs,
00126                                     \textcolor{keyword}{typename} Self::CoeffReturnType* output, \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}* semaphore) \{
00127 \textcolor{preprocessor}{#if \_\_CUDA\_ARCH\_\_ >= 300}
00128   \textcolor{comment}{// Initialize the output value}
00129   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} first\_index = blockIdx.x * BlockSize * NumPerThread + threadIdx.x;
00130   \textcolor{keywordflow}{if} (gridDim.x == 1) \{
00131     \textcolor{keywordflow}{if} (first\_index == 0) \{
00132       *output = reducer.initialize();
00133     \}
00134   \}
00135   \textcolor{keywordflow}{else} \{
00136     \textcolor{keywordflow}{if} (threadIdx.x == 0) \{
00137       \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} block = atomicCAS(semaphore, 0u, 1u);
00138       \textcolor{keywordflow}{if} (block == 0) \{
00139         \textcolor{comment}{// We're the first block to run, initialize the output value}
00140         atomicExchCustom(output, reducer.initialize());
00141         \_\_threadfence();
00142         atomicExch(semaphore, 2u);
00143       \}
00144       \textcolor{keywordflow}{else} \{
00145         \textcolor{comment}{// Wait for the first block to initialize the output value.}
00146         \textcolor{comment}{// Use atomicCAS here to ensure that the reads aren't cached}
00147         \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int} val;
00148         \textcolor{keywordflow}{do} \{
00149           val = atomicCAS(semaphore, 2u, 2u);
00150         \}
00151         \textcolor{keywordflow}{while} (val < 2u);
00152       \}
00153     \}
00154   \}
00155 
00156   \_\_syncthreads();
00157 
00158   eigen\_assert(gridDim.x == 1 || *semaphore >= 2u);
00159 
00160   \textcolor{keyword}{typename} Self::CoeffReturnType accum = reducer.initialize();
00161   \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} max\_iter = numext::mini<Index>(num\_coeffs - first\_index, NumPerThread*BlockSize);
00162   \textcolor{keywordflow}{for} (\hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} i = 0; i < max\_iter; i+=BlockSize) \{
00163     \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} index = first\_index + i;
00164     eigen\_assert(index < num\_coeffs);
00165     \textcolor{keyword}{typename} Self::CoeffReturnType val = input.m\_impl.coeff(index);
00166     reducer.reduce(val, &accum);
00167   \}
00168 
00169 \textcolor{preprocessor}{#pragma unroll}
00170   \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} offset = warpSize/2; offset > 0; offset /= 2) \{
00171     reducer.reduce(\_\_shfl\_down(accum, offset, warpSize), &accum);
00172   \}
00173 
00174   \textcolor{keywordflow}{if} ((threadIdx.x & (warpSize - 1)) == 0) \{
00175     atomicReduce(output, accum, reducer);
00176   \}
00177 
00178   \textcolor{keywordflow}{if} (gridDim.x > 1 && threadIdx.x == 0) \{
00179     \textcolor{comment}{// Let the last block reset the semaphore}
00180     atomicInc(semaphore, gridDim.x + 1);
00181   \}
00182 \textcolor{preprocessor}{#else}
00183   assert(0 && \textcolor{stringliteral}{"Shouldn't be called on unsupported device"});
00184 \textcolor{preprocessor}{#endif}
00185 \}
00186 
00187 
00188 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00189 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self,
00190           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index}>
00191 \_\_global\_\_ \textcolor{keywordtype}{void} ReductionInitFullReduxKernelHalfFloat(Reducer reducer, \textcolor{keyword}{const} Self input, 
      \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_coeffs, half2* scratch) \{
00192   eigen\_assert(blockDim.x == 1);
00193   eigen\_assert(gridDim.x == 1);
00194   \textcolor{keywordflow}{if} (num\_coeffs % 2 != 0) \{
00195     half last = input.m\_impl.coeff(num\_coeffs-1);
00196     *scratch = \_\_halves2half2(last, reducer.initialize());
00197   \} \textcolor{keywordflow}{else} \{
00198     *scratch = reducer.template initializePacket<half2>();
00199   \}
00200 \}
00201 
00202 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self,
00203           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index}>
00204 \_\_global\_\_ \textcolor{keywordtype}{void} ReductionInitKernelHalfFloat(Reducer reducer, \textcolor{keyword}{const} Self input, 
      \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_coeffs, half* output) \{
00205   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} thread\_id = blockIdx.x * blockDim.x + threadIdx.x;
00206   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_threads = blockDim.x * gridDim.x;
00207   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_packets = num\_coeffs / 2;
00208   \textcolor{keywordflow}{for} (\hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} i = thread\_id; i < num\_packets; i += num\_threads) \{
00209     ((half2*)output)[i] = reducer.template initializePacket<half2>();
00210   \}
00211 
00212   \textcolor{keywordflow}{if} (thread\_id == 0 && num\_coeffs % 2 != 0) \{
00213     output[num\_coeffs-1] = reducer.initialize();
00214   \}
00215 \}
00216 
00217 \textcolor{keyword}{template} <\textcolor{keywordtype}{int} BlockSize, \textcolor{keywordtype}{int} NumPerThread, \textcolor{keyword}{typename} Self,
00218           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index}>
00219 \_\_global\_\_ \textcolor{keywordtype}{void} FullReductionKernelHalfFloat(Reducer reducer, \textcolor{keyword}{const} Self input, 
      \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} num\_coeffs,
00220                                     half* output, half2* scratch) \{
00221   eigen\_assert(NumPerThread % 2 == 0);
00222 
00223   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} first\_index = blockIdx.x * BlockSize * NumPerThread + 2*threadIdx.x;
00224 
00225   \textcolor{comment}{// Initialize the output value if it wasn't initialized by the ReductionInitKernel}
00226   \textcolor{keywordflow}{if} (gridDim.x == 1 && first\_index == 0) \{
00227     \textcolor{keywordflow}{if} (num\_coeffs % 2 != 0) \{
00228       half last = input.m\_impl.coeff(num\_coeffs-1);
00229       *scratch = \_\_halves2half2(last, reducer.initialize());
00230     \} \textcolor{keywordflow}{else} \{
00231       *scratch = reducer.template initializePacket<half2>();
00232     \}
00233     \_\_syncthreads();
00234   \}
00235 
00236   half2 accum = reducer.template initializePacket<half2>();
00237   \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} max\_iter = numext::mini<Index>((num\_coeffs - first\_index) / 2, NumPerThread*BlockSize / 
      2);
00238   \textcolor{keywordflow}{for} (\hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} i = 0; i < max\_iter; i += BlockSize) \{
00239     \textcolor{keyword}{const} \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index} index = first\_index + 2*i;
00240     eigen\_assert(index + 1 < num\_coeffs);
00241     half2 val = input.m\_impl.template packet<Unaligned>(index);
00242     reducer.reducePacket(val, &accum);
00243   \}
00244 
00245 \textcolor{preprocessor}{#pragma unroll}
00246   \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} offset = warpSize/2; offset > 0; offset /= 2) \{
00247     reducer.reducePacket(\_\_shfl\_down(accum, offset, warpSize), &accum);
00248   \}
00249 
00250   \textcolor{keywordflow}{if} ((threadIdx.x & (warpSize - 1)) == 0) \{
00251     atomicReduce(scratch, accum, reducer);
00252   \}
00253 
00254   \_\_syncthreads();
00255 
00256   \textcolor{keywordflow}{if} (gridDim.x == 1 && first\_index == 0) \{
00257     half tmp = \_\_low2half(*scratch);
00258     reducer.reduce(\_\_high2half(*scratch), &tmp);
00259     *output = tmp;
00260   \}
00261 \}
00262 
00263 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Op>
00264 \_\_global\_\_ \textcolor{keywordtype}{void} ReductionCleanupKernelHalfFloat(Op& reducer, half* output, half2* scratch) \{
00265   eigen\_assert(threadIdx.x == 1);
00266   half tmp = \_\_low2half(*scratch);
00267   reducer.reduce(\_\_high2half(*scratch), &tmp);
00268   *output = tmp;
00269 \}
00270 
00271 \textcolor{preprocessor}{#endif}
00272 
00273 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op, \textcolor{keyword}{typename} OutputType, \textcolor{keywordtype}{bool} PacketAccess, \textcolor{keyword}{typename} Enabled = \textcolor{keywordtype}{void}>
00274 \textcolor{keyword}{struct }FullReductionLauncher \{
00275   \textcolor{keyword}{static} \textcolor{keywordtype}{void} run(\textcolor{keyword}{const} Self&, Op&, \textcolor{keyword}{const} GpuDevice&, OutputType*, \textcolor{keyword}{typename} Self::Index) \{
00276     assert(\textcolor{keyword}{false} && \textcolor{stringliteral}{"Should only be called on doubles, floats and half floats"});
00277   \}
00278 \};
00279 
00280 \textcolor{comment}{// Specialization for float and double}
00281 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op, \textcolor{keyword}{typename} OutputType, \textcolor{keywordtype}{bool} PacketAccess>
00282 \textcolor{keyword}{struct }FullReductionLauncher<
00283     Self, Op, OutputType, PacketAccess,
00284     typename \hyperlink{namespaceinternal}{internal}::enable\_if<
00285       internal::is\_same<float, OutputType>::value ||
00286       internal::is\_same<double, OutputType>::value,
00287     void>::type> \{
00288   \textcolor{keyword}{static} \textcolor{keywordtype}{void} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, OutputType* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs) \{
00289     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::Index \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index};
00290     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::CoeffReturnType Scalar;
00291     \textcolor{keyword}{const} \textcolor{keywordtype}{int} block\_size = 256;
00292     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_per\_thread = 128;
00293     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = divup<int>(num\_coeffs, block\_size * num\_per\_thread);
00294 
00295     \textcolor{keywordtype}{unsigned} \textcolor{keywordtype}{int}* semaphore = NULL;
00296     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00297       semaphore = device.semaphore();
00298     \}
00299 
00300     LAUNCH\_CUDA\_KERNEL((FullReductionKernel<block\_size, num\_per\_thread, Self, Op, Index>),
00301                        num\_blocks, block\_size, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs, output, semaphore);
00302   \}
00303 \};
00304 
00305 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00306 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00307 \textcolor{keyword}{struct }FullReductionLauncher<Self, Op, \hyperlink{namespace_eigen}{Eigen}::half, false> \{
00308   \textcolor{keyword}{static} \textcolor{keywordtype}{void} run(\textcolor{keyword}{const} Self&, Op&, \textcolor{keyword}{const} GpuDevice&, half*, \textcolor{keyword}{typename} Self::Index) \{
00309     assert(\textcolor{keyword}{false} && \textcolor{stringliteral}{"Should not be called since there is no packet accessor"});
00310   \}
00311 \};
00312 
00313 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00314 \textcolor{keyword}{struct }FullReductionLauncher<Self, Op, \hyperlink{namespace_eigen}{Eigen}::half, true> \{
00315   \textcolor{keyword}{static} \textcolor{keywordtype}{void} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, half* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs) \{
00316     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::Index \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index};
00317 
00318     \textcolor{keyword}{const} \textcolor{keywordtype}{int} block\_size = 256;
00319     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_per\_thread = 128;
00320     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = divup<int>(num\_coeffs, block\_size * num\_per\_thread);
00321     half2* scratch = \textcolor{keyword}{static\_cast<}half2*\textcolor{keyword}{>}(device.scratchpad());
00322 
00323     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00324       \textcolor{comment}{// We initialize the output and the scrathpad outside the reduction kernel when we can't be sure that
       there}
00325       \textcolor{comment}{// won't be a race conditions between multiple thread blocks.}
00326       LAUNCH\_CUDA\_KERNEL((ReductionInitFullReduxKernelHalfFloat<Self, Op, Index>),
00327                          1, 1, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs, scratch);
00328     \}
00329 
00330     LAUNCH\_CUDA\_KERNEL((FullReductionKernelHalfFloat<block\_size, num\_per\_thread, Self, Op, Index>),
00331                        num\_blocks, block\_size, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs, output, scratch);
00332 
00333     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00334       LAUNCH\_CUDA\_KERNEL((ReductionCleanupKernelHalfFloat<Op>),
00335                          1, 1, 0, device, reducer, output, scratch);
00336     \}
00337   \}
00338 \};
00339 \textcolor{preprocessor}{#endif}
00340 
00341 
00342 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op, \textcolor{keywordtype}{bool} Vectorizable>
00343 \textcolor{keyword}{struct }FullReducer<Self, Op, GpuDevice, Vectorizable> \{
00344   \textcolor{comment}{// Unfortunately nvidia doesn't support well exotic types such as complex,}
00345   \textcolor{comment}{// so reduce the scope of the optimized version of the code to the simple cases}
00346   \textcolor{comment}{// of doubles, floats and half floats}
00347 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00348   \textcolor{keyword}{static} \textcolor{keyword}{const} \textcolor{keywordtype}{bool} HasOptimizedImplementation = !Op::IsStateful &&
00349       (internal::is\_same<typename Self::CoeffReturnType, float>::value ||
00350        internal::is\_same<typename Self::CoeffReturnType, double>::value ||
00351        (internal::is\_same<typename Self::CoeffReturnType, Eigen::half>::value && reducer\_traits<Op,
       GpuDevice>::PacketAccess));
00352 \textcolor{preprocessor}{#else}
00353   \textcolor{keyword}{static} \textcolor{keyword}{const} \textcolor{keywordtype}{bool} HasOptimizedImplementation = !Op::IsStateful &&
00354                                                 (internal::is\_same<typename Self::CoeffReturnType,
       float>::value ||
00355                                                  internal::is\_same<typename Self::CoeffReturnType,
       double>::value);
00356 \textcolor{preprocessor}{#endif}
00357 
00358   \textcolor{keyword}{template} <\textcolor{keyword}{typename} OutputType>
00359   \textcolor{keyword}{static} \textcolor{keywordtype}{void} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, OutputType* output) \{
00360     assert(HasOptimizedImplementation && \textcolor{stringliteral}{"Should only be called on doubles, floats or half floats"});
00361     \textcolor{keyword}{const} Index num\_coeffs = array\_prod(\textcolor{keyword}{self}.m\_impl.dimensions());
00362     \textcolor{comment}{// Don't crash when we're called with an input tensor of size 0.}
00363     \textcolor{keywordflow}{if} (num\_coeffs == 0) \{
00364       \textcolor{keywordflow}{return};
00365     \}
00366 
00367     FullReductionLauncher<Self, Op, OutputType, reducer\_traits<Op, GpuDevice>::PacketAccess>::run(\textcolor{keyword}{self}, 
      reducer, device, output, num\_coeffs);
00368   \}
00369 \};
00370 
00371 
00372 \textcolor{keyword}{template} <\textcolor{keywordtype}{int} NumPerThread, \textcolor{keyword}{typename} Self,
00373           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} Index>
00374 \_\_global\_\_ \textcolor{keywordtype}{void} InnerReductionKernel(Reducer reducer, \textcolor{keyword}{const} Self input, Index num\_coeffs\_to\_reduce, Index 
      num\_preserved\_coeffs,
00375                                          \textcolor{keyword}{typename} Self::CoeffReturnType* output) \{
00376 \textcolor{preprocessor}{#if \_\_CUDA\_ARCH\_\_ >= 300}
00377   \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::CoeffReturnType Type;
00378   eigen\_assert(blockDim.y == 1);
00379   eigen\_assert(blockDim.z == 1);
00380   eigen\_assert(gridDim.y == 1);
00381   eigen\_assert(gridDim.z == 1);
00382 
00383   \textcolor{keyword}{const} \textcolor{keywordtype}{int} unroll\_times = 16;
00384   eigen\_assert(NumPerThread % unroll\_times == 0);
00385 
00386   \textcolor{keyword}{const} Index input\_col\_blocks = divup<Index>(num\_coeffs\_to\_reduce, blockDim.x * NumPerThread);
00387   \textcolor{keyword}{const} Index num\_input\_blocks = input\_col\_blocks * num\_preserved\_coeffs;
00388 
00389   \textcolor{keyword}{const} Index num\_threads = blockDim.x * gridDim.x;
00390   \textcolor{keyword}{const} Index thread\_id = blockIdx.x * blockDim.x + threadIdx.x;
00391 
00392   \textcolor{comment}{// Initialize the output values if they weren't initialized by the ReductionInitKernel}
00393   \textcolor{keywordflow}{if} (gridDim.x == 1) \{
00394     \textcolor{keywordflow}{for} (Index i = thread\_id; i < num\_preserved\_coeffs; i += num\_threads) \{
00395       output[i] = reducer.initialize();
00396     \}
00397     \_\_syncthreads();
00398   \}
00399 
00400   \textcolor{keywordflow}{for} (Index i = blockIdx.x; i < num\_input\_blocks; i += gridDim.x) \{
00401     \textcolor{keyword}{const} Index row = i / input\_col\_blocks;
00402 
00403     \textcolor{keywordflow}{if} (row < num\_preserved\_coeffs) \{
00404       \textcolor{keyword}{const} Index col\_block = i % input\_col\_blocks;
00405       \textcolor{keyword}{const} Index col\_begin = col\_block * blockDim.x * NumPerThread + threadIdx.x;
00406 
00407       Type reduced\_val = reducer.initialize();
00408 
00409       \textcolor{keywordflow}{for} (Index j = 0; j < NumPerThread; j += unroll\_times) \{
00410         \textcolor{keyword}{const} Index last\_col = col\_begin + blockDim.x * (j + unroll\_times - 1);
00411         \textcolor{keywordflow}{if} (last\_col >= num\_coeffs\_to\_reduce) \{
00412           \textcolor{keywordflow}{for} (Index col = col\_begin + blockDim.x * j; col < num\_coeffs\_to\_reduce; col += blockDim.x) \{
00413             \textcolor{keyword}{const} Type val = input.m\_impl.coeff(row * num\_coeffs\_to\_reduce + col);
00414             reducer.reduce(val, &reduced\_val);
00415           \}
00416           \textcolor{keywordflow}{break};
00417         \} \textcolor{keywordflow}{else} \{
00418           \textcolor{comment}{// Faster version of the loop with no branches after unrolling.}
00419 \textcolor{preprocessor}{#pragma unroll}
00420           \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} k = 0; k < unroll\_times; ++k) \{
00421             \textcolor{keyword}{const} Index col = col\_begin + blockDim.x * (j + k);
00422             reducer.reduce(input.m\_impl.coeff(row * num\_coeffs\_to\_reduce + col), &reduced\_val);
00423           \}
00424         \}
00425       \}
00426 
00427 \textcolor{preprocessor}{#pragma unroll}
00428       \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} offset = warpSize/2; offset > 0; offset /= 2) \{
00429         reducer.reduce(\_\_shfl\_down(reduced\_val, offset), &reduced\_val);
00430       \}
00431 
00432       \textcolor{keywordflow}{if} ((threadIdx.x & (warpSize - 1)) == 0) \{
00433         atomicReduce(&(output[row]), reduced\_val, reducer);
00434       \}
00435     \}
00436   \}
00437 \textcolor{preprocessor}{#else}
00438   assert(0 && \textcolor{stringliteral}{"Shouldn't be called on unsupported device"});
00439 \textcolor{preprocessor}{#endif}
00440 \}
00441 
00442 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00443 
00444 \textcolor{keyword}{template} <\textcolor{keywordtype}{int} NumPerThread, \textcolor{keyword}{typename} Self,
00445           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} Index>
00446 \_\_global\_\_ \textcolor{keywordtype}{void} InnerReductionKernelHalfFloat(Reducer reducer, \textcolor{keyword}{const} Self input, Index num\_coeffs\_to\_reduce
      , Index num\_preserved\_coeffs,
00447                                               half* output) \{
00448   eigen\_assert(blockDim.y == 1);
00449   eigen\_assert(blockDim.z == 1);
00450   eigen\_assert(gridDim.y == 1);
00451   eigen\_assert(gridDim.z == 1);
00452 
00453   \textcolor{keyword}{const} \textcolor{keywordtype}{int} unroll\_times = 16;
00454   eigen\_assert(NumPerThread % unroll\_times == 0);
00455   eigen\_assert(unroll\_times % 2 == 0);
00456 
00457   \textcolor{keyword}{const} Index input\_col\_blocks = divup<Index>(num\_coeffs\_to\_reduce, blockDim.x * NumPerThread * 2);
00458   \textcolor{keyword}{const} Index num\_input\_blocks = divup<Index>(input\_col\_blocks * num\_preserved\_coeffs, 2);
00459 
00460   \textcolor{keyword}{const} Index num\_threads = blockDim.x * gridDim.x;
00461   \textcolor{keyword}{const} Index thread\_id = blockIdx.x * blockDim.x + threadIdx.x;
00462 
00463   \textcolor{comment}{// Initialize the output values if they weren't initialized by the ReductionInitKernel}
00464   \textcolor{keywordflow}{if} (gridDim.x == 1) \{
00465     Index i = 2*thread\_id;
00466     \textcolor{keywordflow}{for} (; i + 1 < num\_preserved\_coeffs; i += 2*num\_threads) \{
00467       half* loc = output + i;
00468       *((half2*)loc) = reducer.template initializePacket<half2>();
00469     \}
00470     \textcolor{keywordflow}{if} (i < num\_preserved\_coeffs) \{
00471       output[i] = reducer.initialize();
00472     \}
00473     \_\_syncthreads();
00474   \}
00475 
00476   \textcolor{keywordflow}{for} (Index i = blockIdx.x; i < num\_input\_blocks; i += gridDim.x) \{
00477     \textcolor{keyword}{const} Index row = 2 * (i / input\_col\_blocks);
00478 
00479     \textcolor{keywordflow}{if} (row + 1 < num\_preserved\_coeffs) \{
00480       \textcolor{keyword}{const} Index col\_block = i % input\_col\_blocks;
00481       \textcolor{keyword}{const} Index col\_begin = 2 * (col\_block * blockDim.x * NumPerThread + threadIdx.x);
00482 
00483       half2 reduced\_val1 = reducer.template initializePacket<half2>();
00484       half2 reduced\_val2 = reducer.template initializePacket<half2>();
00485 
00486       \textcolor{keywordflow}{for} (Index j = 0; j < NumPerThread; j += unroll\_times) \{
00487         \textcolor{keyword}{const} Index last\_col = col\_begin + blockDim.x * (j + unroll\_times - 1) * 2;
00488         \textcolor{keywordflow}{if} (last\_col >= num\_coeffs\_to\_reduce) \{
00489           Index col = col\_begin + blockDim.x * j;
00490           \textcolor{keywordflow}{for} (; col + 1 < num\_coeffs\_to\_reduce; col += blockDim.x) \{
00491             \textcolor{keyword}{const} half2 val1 = input.m\_impl.template packet<Unaligned>(row * num\_coeffs\_to\_reduce + col);
00492             reducer.reducePacket(val1, &reduced\_val1);
00493             \textcolor{keyword}{const} half2 val2 = input.m\_impl.template packet<Unaligned>((row+1) * num\_coeffs\_to\_reduce + col
      );
00494             reducer.reducePacket(val2, &reduced\_val2);
00495           \}
00496           \textcolor{keywordflow}{if} (col < num\_coeffs\_to\_reduce) \{
00497             \textcolor{comment}{// Peel;}
00498             \textcolor{keyword}{const} half last1 = input.m\_impl.coeff(row * num\_coeffs\_to\_reduce + col);
00499             \textcolor{keyword}{const} half2 val1 = \_\_halves2half2(last1, reducer.initialize());
00500             reducer.reducePacket(val1, &reduced\_val1);
00501             \textcolor{keyword}{const} half last2 = input.m\_impl.coeff((row+1) * num\_coeffs\_to\_reduce + col);
00502             \textcolor{keyword}{const} half2 val2 = \_\_halves2half2(last2, reducer.initialize());
00503             reducer.reducePacket(val2, &reduced\_val2);
00504           \}
00505           \textcolor{keywordflow}{break};
00506         \} \textcolor{keywordflow}{else} \{
00507           \textcolor{comment}{// Faster version of the loop with no branches after unrolling.}
00508 \textcolor{preprocessor}{#pragma unroll}
00509           \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} k = 0; k < unroll\_times; ++k) \{
00510             \textcolor{keyword}{const} Index col = col\_begin + blockDim.x * (j + k) * 2;
00511             reducer.reducePacket(input.m\_impl.template packet<Unaligned>(row * num\_coeffs\_to\_reduce + col),
       &reduced\_val1);
00512             reducer.reducePacket(input.m\_impl.template packet<Unaligned>((row + 1)* num\_coeffs\_to\_reduce + 
      col), &reduced\_val2);
00513           \}
00514         \}
00515       \}
00516 
00517 \textcolor{preprocessor}{#pragma unroll}
00518       \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} offset = warpSize/2; offset > 0; offset /= 2) \{
00519         reducer.reducePacket(\_\_shfl\_down(reduced\_val1, offset, warpSize), &reduced\_val1);
00520         reducer.reducePacket(\_\_shfl\_down(reduced\_val2, offset, warpSize), &reduced\_val2);
00521       \}
00522 
00523       half val1 =  \_\_low2half(reduced\_val1);
00524       reducer.reduce(\_\_high2half(reduced\_val1), &val1);
00525       half val2 =  \_\_low2half(reduced\_val2);
00526       reducer.reduce(\_\_high2half(reduced\_val2), &val2);
00527       half2 val = \_\_halves2half2(val1, val2);
00528 
00529       \textcolor{keywordflow}{if} ((threadIdx.x & (warpSize - 1)) == 0) \{
00530         half* loc = output + row;
00531         atomicReduce((half2*)loc, val, reducer);
00532       \}
00533     \}
00534   \}
00535 \}
00536 
00537 \textcolor{preprocessor}{#endif}
00538 
00539 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op, \textcolor{keyword}{typename} OutputType, \textcolor{keywordtype}{bool} PacketAccess, \textcolor{keyword}{typename} Enabled = \textcolor{keywordtype}{void}>
00540 \textcolor{keyword}{struct }InnerReductionLauncher \{
00541   \textcolor{keyword}{static} EIGEN\_DEVICE\_FUNC \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self&, Op&, \textcolor{keyword}{const} GpuDevice&, OutputType*, \textcolor{keyword}{typename} Self::Index, \textcolor{keyword}{
      typename} Self::Index) \{
00542     assert(\textcolor{keyword}{false} && \textcolor{stringliteral}{"Should only be called to reduce doubles, floats and half floats on a gpu device"});
00543     \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00544   \}
00545 \};
00546 
00547 \textcolor{comment}{// Specialization for float and double}
00548 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op, \textcolor{keyword}{typename} OutputType, \textcolor{keywordtype}{bool} PacketAccess>
00549 \textcolor{keyword}{struct }InnerReductionLauncher<
00550   Self, Op, OutputType, PacketAccess,
00551   typename \hyperlink{namespaceinternal}{internal}::enable\_if<
00552     internal::is\_same<float, OutputType>::value ||
00553     internal::is\_same<double, OutputType>::value,
00554   void>::type> \{
00555   \textcolor{keyword}{static} \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, OutputType* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs\_to\_reduce, \textcolor{keyword}{typename} Self::Index num\_preserved\_vals) \{
00556     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::Index \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index};
00557 
00558     \textcolor{keyword}{const} Index num\_coeffs = num\_coeffs\_to\_reduce * num\_preserved\_vals;
00559     \textcolor{keyword}{const} \textcolor{keywordtype}{int} block\_size = 256;
00560     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_per\_thread = 128;
00561     \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_coeffs, block\_size * num\_per\_thread);
00562     \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00563                            device.maxCudaThreadsPerMultiProcessor() / block\_size;
00564     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00565 
00566     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00567       \textcolor{comment}{// We initialize the outputs outside the reduction kernel when we can't be sure that there}
00568       \textcolor{comment}{// won't be a race conditions between multiple thread blocks.}
00569       \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_preserved\_vals, 1024);
00570       \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00571                            device.maxCudaThreadsPerMultiProcessor() / 1024;
00572       \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00573       LAUNCH\_CUDA\_KERNEL((ReductionInitKernel<OutputType, Index>),
00574                          num\_blocks, 1024, 0, device, reducer.initialize(),
00575                          num\_preserved\_vals, output);
00576     \}
00577 
00578     LAUNCH\_CUDA\_KERNEL((InnerReductionKernel<num\_per\_thread, Self, Op, Index>),
00579                        num\_blocks, block\_size, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs\_to\_reduce, 
      num\_preserved\_vals, output);
00580 
00581     \textcolor{keywordflow}{return} \textcolor{keyword}{false};
00582   \}
00583 \};
00584 
00585 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00586 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00587 \textcolor{keyword}{struct }InnerReductionLauncher<Self, Op, \hyperlink{namespace_eigen}{Eigen}::half, false> \{
00588   \textcolor{keyword}{static} \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self&, Op&, \textcolor{keyword}{const} GpuDevice&, half*, \textcolor{keyword}{typename} Self::Index, \textcolor{keyword}{typename} Self::Index) \{
00589     assert(\textcolor{keyword}{false} && \textcolor{stringliteral}{"Should not be called since there is no packet accessor"});
00590     \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00591   \}
00592 \};
00593 
00594 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00595 \textcolor{keyword}{struct }InnerReductionLauncher<Self, Op, \hyperlink{namespace_eigen}{Eigen}::half, true> \{
00596   \textcolor{keyword}{static} \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, half* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs\_to\_reduce, \textcolor{keyword}{typename} Self::Index num\_preserved\_vals) \{
00597     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::Index \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index};
00598 
00599     \textcolor{keywordflow}{if} (num\_preserved\_vals % 2 != 0) \{
00600       \textcolor{comment}{// Not supported yet, revert to the slower code path}
00601       \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00602     \}
00603 
00604     \textcolor{keyword}{const} Index num\_coeffs = num\_coeffs\_to\_reduce * num\_preserved\_vals;
00605     \textcolor{keyword}{const} \textcolor{keywordtype}{int} block\_size = \textcolor{comment}{/*256*/}128;
00606     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_per\_thread = \textcolor{comment}{/*128*/}64;
00607     \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_coeffs, block\_size * num\_per\_thread);
00608     \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00609                            device.maxCudaThreadsPerMultiProcessor() / block\_size;
00610     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00611 
00612     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00613       \textcolor{comment}{// We initialize the outputs outside the reduction kernel when we can't be sure that there}
00614       \textcolor{comment}{// won't be a race conditions between multiple thread blocks.}
00615       \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_preserved\_vals, 1024);
00616       \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00617                            device.maxCudaThreadsPerMultiProcessor() / 1024;
00618       \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00619       LAUNCH\_CUDA\_KERNEL((ReductionInitKernelHalfFloat<Self, Op, Index>),
00620                          1, 1, 0, device, reducer, \textcolor{keyword}{self}, num\_preserved\_vals, output);
00621     \}
00622 
00623     LAUNCH\_CUDA\_KERNEL((InnerReductionKernelHalfFloat<num\_per\_thread, Self, Op, Index>),
00624                        num\_blocks, block\_size, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs\_to\_reduce, 
      num\_preserved\_vals, output);
00625 
00626     \textcolor{keywordflow}{return} \textcolor{keyword}{false};
00627   \}
00628 \};
00629 \textcolor{preprocessor}{#endif}
00630 
00631 
00632 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00633 \textcolor{keyword}{struct }InnerReducer<Self, Op, GpuDevice> \{
00634   \textcolor{comment}{// Unfortunately nvidia doesn't support well exotic types such as complex,}
00635   \textcolor{comment}{// so reduce the scope of the optimized version of the code to the simple case}
00636   \textcolor{comment}{// of floats and half floats.}
00637 \textcolor{preprocessor}{#ifdef EIGEN\_HAS\_CUDA\_FP16}
00638   \textcolor{keyword}{static} \textcolor{keyword}{const} \textcolor{keywordtype}{bool} HasOptimizedImplementation = !Op::IsStateful &&
00639       (internal::is\_same<typename Self::CoeffReturnType, float>::value ||
00640        internal::is\_same<typename Self::CoeffReturnType, double>::value ||
00641        (internal::is\_same<typename Self::CoeffReturnType, Eigen::half>::value && reducer\_traits<Op,
       GpuDevice>::PacketAccess));
00642 \textcolor{preprocessor}{#else}
00643   \textcolor{keyword}{static} \textcolor{keyword}{const} \textcolor{keywordtype}{bool} HasOptimizedImplementation = !Op::IsStateful &&
00644                                                  (internal::is\_same<typename Self::CoeffReturnType,
       float>::value ||
00645                                                   internal::is\_same<typename Self::CoeffReturnType,
       double>::value);
00646 \textcolor{preprocessor}{#endif}
00647 
00648   \textcolor{keyword}{template} <\textcolor{keyword}{typename} OutputType>
00649   \textcolor{keyword}{static} \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, OutputType* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs\_to\_reduce, \textcolor{keyword}{typename} Self::Index num\_preserved\_vals) \{
00650     assert(HasOptimizedImplementation && \textcolor{stringliteral}{"Should only be called on doubles, floats or half floats"});
00651     \textcolor{keyword}{const} Index num\_coeffs = array\_prod(\textcolor{keyword}{self}.m\_impl.dimensions());
00652     \textcolor{comment}{// Don't crash when we're called with an input tensor of size 0.}
00653     \textcolor{keywordflow}{if} (num\_coeffs == 0) \{
00654       \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00655     \}
00656     \textcolor{comment}{// It's faster to use the usual code.}
00657     \textcolor{keywordflow}{if} (num\_coeffs\_to\_reduce <= 128) \{
00658       \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00659     \}
00660 
00661     \textcolor{keywordflow}{return} InnerReductionLauncher<Self, Op, OutputType, reducer\_traits<Op, GpuDevice>::PacketAccess>::run(\textcolor{keyword}{
      self}, reducer, device, output, num\_coeffs\_to\_reduce, num\_preserved\_vals);
00662   \}
00663 \};
00664 
00665 \textcolor{keyword}{template} <\textcolor{keywordtype}{int} NumPerThread, \textcolor{keyword}{typename} Self,
00666           \textcolor{keyword}{typename} Reducer, \textcolor{keyword}{typename} Index>
00667 \_\_global\_\_ \textcolor{keywordtype}{void} OuterReductionKernel(Reducer reducer, \textcolor{keyword}{const} Self input, Index num\_coeffs\_to\_reduce, Index 
      num\_preserved\_coeffs,
00668                                      \textcolor{keyword}{typename} Self::CoeffReturnType* output) \{
00669   \textcolor{keyword}{const} Index num\_threads = blockDim.x * gridDim.x;
00670   \textcolor{keyword}{const} Index thread\_id = blockIdx.x * blockDim.x + threadIdx.x;
00671   \textcolor{comment}{// Initialize the output values if they weren't initialized by the ReductionInitKernel}
00672   \textcolor{keywordflow}{if} (gridDim.x == 1) \{
00673     \textcolor{keywordflow}{for} (Index i = thread\_id; i < num\_preserved\_coeffs; i += num\_threads) \{
00674       output[i] = reducer.initialize();
00675     \}
00676     \_\_syncthreads();
00677   \}
00678 
00679   \textcolor{comment}{// Do the reduction.}
00680   \textcolor{keyword}{const} Index max\_iter = num\_preserved\_coeffs * divup<Index>(num\_coeffs\_to\_reduce, NumPerThread);
00681   \textcolor{keywordflow}{for} (Index i = thread\_id; i < max\_iter; i += num\_threads) \{
00682     \textcolor{keyword}{const} Index input\_col = i % num\_preserved\_coeffs;
00683     \textcolor{keyword}{const} Index input\_row = (i / num\_preserved\_coeffs) * NumPerThread;
00684     \textcolor{keyword}{typename} Self::CoeffReturnType reduced\_val = reducer.initialize();
00685     \textcolor{keyword}{const} Index max\_row = numext::mini(input\_row + NumPerThread, num\_coeffs\_to\_reduce);
00686     \textcolor{keywordflow}{for} (Index j = input\_row; j < max\_row; j++) \{
00687       \textcolor{keyword}{typename} Self::CoeffReturnType val = input.m\_impl.coeff(j * num\_preserved\_coeffs + input\_col);
00688       reducer.reduce(val, &reduced\_val);
00689     \}
00690     atomicReduce(&(output[input\_col]), reduced\_val, reducer);
00691   \}
00692 \}
00693 
00694 
00695 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Self, \textcolor{keyword}{typename} Op>
00696 \textcolor{keyword}{struct }OuterReducer<Self, Op, GpuDevice> \{
00697   \textcolor{comment}{// Unfortunately nvidia doesn't support well exotic types such as complex,}
00698   \textcolor{comment}{// so reduce the scope of the optimized version of the code to the simple case}
00699   \textcolor{comment}{// of floats.}
00700   \textcolor{keyword}{static} \textcolor{keyword}{const} \textcolor{keywordtype}{bool} HasOptimizedImplementation = !Op::IsStateful &&
00701                                                  (internal::is\_same<typename Self::CoeffReturnType,
       float>::value ||
00702                                                   internal::is\_same<typename Self::CoeffReturnType,
       double>::value);
00703   \textcolor{keyword}{template} <\textcolor{keyword}{typename} Device, \textcolor{keyword}{typename} OutputType>
00704   \textcolor{keyword}{static} EIGEN\_DEVICE\_FUNC \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self&, Op&, \textcolor{keyword}{const} Device&, OutputType*, \textcolor{keyword}{typename} Self::Index, \textcolor{keyword}{
      typename} Self::Index) \{
00705     assert(\textcolor{keyword}{false} && \textcolor{stringliteral}{"Should only be called to reduce doubles or floats on a gpu device"});
00706     \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00707   \}
00708 
00709   \textcolor{keyword}{static} \textcolor{keywordtype}{bool} run(\textcolor{keyword}{const} Self& \textcolor{keyword}{self}, Op& reducer, \textcolor{keyword}{const} GpuDevice& device, \textcolor{keywordtype}{float}* output, \textcolor{keyword}{typename} 
      Self::Index num\_coeffs\_to\_reduce, \textcolor{keyword}{typename} Self::Index num\_preserved\_vals) \{
00710     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Self::Index \hyperlink{namespace_eigen_a62e77e0933482dafde8fe197d9a2cfde}{Index};
00711 
00712     \textcolor{comment}{// It's faster to use the usual code.}
00713     \textcolor{keywordflow}{if} (num\_coeffs\_to\_reduce <= 32) \{
00714       \textcolor{keywordflow}{return} \textcolor{keyword}{true};
00715     \}
00716 
00717     \textcolor{keyword}{const} Index num\_coeffs = num\_coeffs\_to\_reduce * num\_preserved\_vals;
00718     \textcolor{keyword}{const} \textcolor{keywordtype}{int} block\_size = 256;
00719     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_per\_thread = 16;
00720     \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_coeffs, block\_size * num\_per\_thread);
00721     \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00722                            device.maxCudaThreadsPerMultiProcessor() / block\_size;
00723     \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00724 
00725     \textcolor{keywordflow}{if} (num\_blocks > 1) \{
00726       \textcolor{comment}{// We initialize the outputs in the reduction kernel itself when we don't have to worry}
00727       \textcolor{comment}{// about race conditions between multiple thread blocks.}
00728       \textcolor{keyword}{const} \textcolor{keywordtype}{int} dyn\_blocks = divup<int>(num\_preserved\_vals, 1024);
00729       \textcolor{keyword}{const} \textcolor{keywordtype}{int} max\_blocks = device.getNumCudaMultiProcessors() *
00730                              device.maxCudaThreadsPerMultiProcessor() / 1024;
00731       \textcolor{keyword}{const} \textcolor{keywordtype}{int} num\_blocks = numext::mini<int>(max\_blocks, dyn\_blocks);
00732       LAUNCH\_CUDA\_KERNEL((ReductionInitKernel<float, Index>),
00733                          num\_blocks, 1024, 0, device, reducer.initialize(),
00734                          num\_preserved\_vals, output);
00735     \}
00736 
00737     LAUNCH\_CUDA\_KERNEL((OuterReductionKernel<num\_per\_thread, Self, Op, Index>),
00738                        num\_blocks, block\_size, 0, device, reducer, \textcolor{keyword}{self}, num\_coeffs\_to\_reduce, 
      num\_preserved\_vals, output);
00739 
00740     \textcolor{keywordflow}{return} \textcolor{keyword}{false};
00741   \}
00742 \};
00743 
00744 \textcolor{preprocessor}{#endif}
00745 
00746 
00747 \} \textcolor{comment}{// end namespace internal}
00748 \} \textcolor{comment}{// end namespace Eigen}
00749 
00750 \textcolor{preprocessor}{#endif // EIGEN\_CXX11\_TENSOR\_TENSOR\_REDUCTION\_CUDA\_H}
\end{DoxyCode}
