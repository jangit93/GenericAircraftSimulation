\hypertarget{eigen_2test_2cuda__common_8h_source}{}\section{eigen/test/cuda\+\_\+common.h}
\label{eigen_2test_2cuda__common_8h_source}\index{cuda\+\_\+common.\+h@{cuda\+\_\+common.\+h}}

\begin{DoxyCode}
00001 
00002 \textcolor{preprocessor}{#ifndef EIGEN\_TEST\_CUDA\_COMMON\_H}
00003 \textcolor{preprocessor}{#define EIGEN\_TEST\_CUDA\_COMMON\_H}
00004 
00005 \textcolor{preprocessor}{#include <cuda.h>}
00006 \textcolor{preprocessor}{#include <cuda\_runtime.h>}
00007 \textcolor{preprocessor}{#include <cuda\_runtime\_api.h>}
00008 \textcolor{preprocessor}{#include <iostream>}
00009 
00010 \textcolor{preprocessor}{#ifndef \_\_CUDACC\_\_}
00011 dim3 threadIdx, blockDim, blockIdx;
00012 \textcolor{preprocessor}{#endif}
00013 
00014 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Kernel, \textcolor{keyword}{typename} Input, \textcolor{keyword}{typename} Output>
00015 \textcolor{keywordtype}{void} run\_on\_cpu(\textcolor{keyword}{const} Kernel& ker, \textcolor{keywordtype}{int} n, \textcolor{keyword}{const} Input& in, Output& out)
00016 \{
00017   \textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i=0; i<n; i++)
00018     ker(i, in.data(), out.data());
00019 \}
00020 
00021 
00022 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Kernel, \textcolor{keyword}{typename} Input, \textcolor{keyword}{typename} Output>
00023 \_\_global\_\_
00024 \textcolor{keywordtype}{void} run\_on\_cuda\_meta\_kernel(\textcolor{keyword}{const} Kernel ker, \textcolor{keywordtype}{int} n, \textcolor{keyword}{const} Input* in, Output* out)
00025 \{
00026   \textcolor{keywordtype}{int} i = threadIdx.x + blockIdx.x*blockDim.x;
00027   \textcolor{keywordflow}{if}(i<n) \{
00028     ker(i, in, out);
00029   \}
00030 \}
00031 
00032 
00033 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Kernel, \textcolor{keyword}{typename} Input, \textcolor{keyword}{typename} Output>
00034 \textcolor{keywordtype}{void} run\_on\_cuda(\textcolor{keyword}{const} Kernel& ker, \textcolor{keywordtype}{int} n, \textcolor{keyword}{const} Input& in, Output& out)
00035 \{
00036   \textcolor{keyword}{typename} Input::Scalar*  d\_in;
00037   \textcolor{keyword}{typename} Output::Scalar* d\_out;
00038   std::ptrdiff\_t in\_bytes  = in.size()  * \textcolor{keyword}{sizeof}(\textcolor{keyword}{typename} Input::Scalar);
00039   std::ptrdiff\_t out\_bytes = out.size() * \textcolor{keyword}{sizeof}(\textcolor{keyword}{typename} Output::Scalar);
00040   
00041   cudaMalloc((\textcolor{keywordtype}{void}**)(&d\_in),  in\_bytes);
00042   cudaMalloc((\textcolor{keywordtype}{void}**)(&d\_out), out\_bytes);
00043   
00044   cudaMemcpy(d\_in,  in.data(),  in\_bytes,  cudaMemcpyHostToDevice);
00045   cudaMemcpy(d\_out, out.data(), out\_bytes, cudaMemcpyHostToDevice);
00046   
00047   \textcolor{comment}{// Simple and non-optimal 1D mapping assuming n is not too large}
00048   \textcolor{comment}{// That's only for unit testing!}
00049   dim3 Blocks(128);
00050   dim3 Grids( (n+\textcolor{keywordtype}{int}(Blocks.x)-1)/\textcolor{keywordtype}{int}(Blocks.x) );
00051 
00052   cudaThreadSynchronize();
00053   run\_on\_cuda\_meta\_kernel<<<Grids,Blocks>>>(ker, n, d\_in, d\_out);
00054   cudaThreadSynchronize();
00055   
00056   \textcolor{comment}{// check inputs have not been modified}
00057   cudaMemcpy(const\_cast<typename Input::Scalar*>(in.data()),  d\_in,  in\_bytes,  cudaMemcpyDeviceToHost);
00058   cudaMemcpy(out.data(), d\_out, out\_bytes, cudaMemcpyDeviceToHost);
00059   
00060   cudaFree(d\_in);
00061   cudaFree(d\_out);
00062 \}
00063 
00064 
00065 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Kernel, \textcolor{keyword}{typename} Input, \textcolor{keyword}{typename} Output>
00066 \textcolor{keywordtype}{void} run\_and\_compare\_to\_cuda(\textcolor{keyword}{const} Kernel& ker, \textcolor{keywordtype}{int} n, \textcolor{keyword}{const} Input& in, Output& out)
00067 \{
00068   Input  in\_ref,  in\_cuda;
00069   Output out\_ref, out\_cuda;
00070 \textcolor{preprocessor}{  #ifndef \_\_CUDA\_ARCH\_\_}
00071   in\_ref = in\_cuda = in;
00072   out\_ref = out\_cuda = out;
00073 \textcolor{preprocessor}{  #endif}
00074   run\_on\_cpu (ker, n, in\_ref,  out\_ref);
00075   run\_on\_cuda(ker, n, in\_cuda, out\_cuda);
00076 \textcolor{preprocessor}{  #ifndef \_\_CUDA\_ARCH\_\_}
00077   VERIFY\_IS\_APPROX(in\_ref, in\_cuda);
00078   VERIFY\_IS\_APPROX(out\_ref, out\_cuda);
00079 \textcolor{preprocessor}{  #endif}
00080 \}
00081 
00082 
00083 \textcolor{keywordtype}{void} ei\_test\_init\_cuda()
00084 \{
00085   \textcolor{keywordtype}{int} device = 0;
00086   cudaDeviceProp deviceProp;
00087   cudaGetDeviceProperties(&deviceProp, device);
00088   std::cout << \textcolor{stringliteral}{"CUDA device info:\(\backslash\)n"};
00089   std::cout << \textcolor{stringliteral}{"  name:                        "} << deviceProp.name << \textcolor{stringliteral}{"\(\backslash\)n"};
00090   std::cout << \textcolor{stringliteral}{"  capability:                  "} << deviceProp.major << \textcolor{stringliteral}{"."} << deviceProp.minor << \textcolor{stringliteral}{"\(\backslash\)n"};
00091   std::cout << \textcolor{stringliteral}{"  multiProcessorCount:         "} << deviceProp.multiProcessorCount << \textcolor{stringliteral}{"\(\backslash\)n"};
00092   std::cout << \textcolor{stringliteral}{"  maxThreadsPerMultiProcessor: "} << deviceProp.maxThreadsPerMultiProcessor << \textcolor{stringliteral}{"\(\backslash\)n"};
00093   std::cout << \textcolor{stringliteral}{"  warpSize:                    "} << deviceProp.warpSize << \textcolor{stringliteral}{"\(\backslash\)n"};
00094   std::cout << \textcolor{stringliteral}{"  regsPerBlock:                "} << deviceProp.regsPerBlock << \textcolor{stringliteral}{"\(\backslash\)n"};
00095   std::cout << \textcolor{stringliteral}{"  concurrentKernels:           "} << deviceProp.concurrentKernels << \textcolor{stringliteral}{"\(\backslash\)n"};
00096   std::cout << \textcolor{stringliteral}{"  clockRate:                   "} << deviceProp.clockRate << \textcolor{stringliteral}{"\(\backslash\)n"};
00097   std::cout << \textcolor{stringliteral}{"  canMapHostMemory:            "} << deviceProp.canMapHostMemory << \textcolor{stringliteral}{"\(\backslash\)n"};
00098   std::cout << \textcolor{stringliteral}{"  computeMode:                 "} << deviceProp.computeMode << \textcolor{stringliteral}{"\(\backslash\)n"};
00099 \}
00100 
00101 \textcolor{preprocessor}{#endif // EIGEN\_TEST\_CUDA\_COMMON\_H}
\end{DoxyCode}
