\hypertarget{eigen_2unsupported_2test_2autodiff_8cpp_source}{}\section{eigen/unsupported/test/autodiff.cpp}
\label{eigen_2unsupported_2test_2autodiff_8cpp_source}\index{autodiff.\+cpp@{autodiff.\+cpp}}

\begin{DoxyCode}
00001 \textcolor{comment}{// This file is part of Eigen, a lightweight C++ template library}
00002 \textcolor{comment}{// for linear algebra.}
00003 \textcolor{comment}{//}
00004 \textcolor{comment}{// Copyright (C) 2009 Gael Guennebaud <g.gael@free.fr>}
00005 \textcolor{comment}{//}
00006 \textcolor{comment}{// This Source Code Form is subject to the terms of the Mozilla}
00007 \textcolor{comment}{// Public License v. 2.0. If a copy of the MPL was not distributed}
00008 \textcolor{comment}{// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.}
00009 
00010 \textcolor{preprocessor}{#include "main.h"}
00011 \textcolor{preprocessor}{#include <unsupported/Eigen/AutoDiff>}
00012 
00013 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Scalar>
00014 EIGEN\_DONT\_INLINE Scalar foo(\textcolor{keyword}{const} Scalar& x, \textcolor{keyword}{const} Scalar& y)
00015 \{
00016   \textcolor{keyword}{using namespace }\hyperlink{namespacestd}{std};
00017 \textcolor{comment}{//   return x+std::sin(y);}
00018   EIGEN\_ASM\_COMMENT(\textcolor{stringliteral}{"mybegin"});
00019   \textcolor{comment}{// pow(float, int) promotes to pow(double, double)}
00020   \textcolor{keywordflow}{return} x*2 - 1 + \textcolor{keyword}{static\_cast<}Scalar\textcolor{keyword}{>}(pow(1+x,2)) + 2*sqrt(y*y+0) - 4 * sin(0+x) + 2 * cos(y+0) - exp(
      Scalar(-0.5)*x*x+0);
00021   \textcolor{comment}{//return x+2*y*x;//x*2 -std::pow(x,2);//(2*y/x);// - y*2;}
00022   EIGEN\_ASM\_COMMENT(\textcolor{stringliteral}{"myend"});
00023 \}
00024 
00025 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Vector>
00026 EIGEN\_DONT\_INLINE \textcolor{keyword}{typename} Vector::Scalar foo(\textcolor{keyword}{const} Vector& p)
00027 \{
00028   \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Vector::Scalar Scalar;
00029   \textcolor{keywordflow}{return} (p-Vector(Scalar(-1),Scalar(1.))).norm() + (p.array() * p.array()).sum() + p.dot(p);
00030 \}
00031 
00032 \textcolor{keyword}{template}<\textcolor{keyword}{typename} \_Scalar, \textcolor{keywordtype}{int} NX=Dynamic, \textcolor{keywordtype}{int} NY=Dynamic>
\Hypertarget{eigen_2unsupported_2test_2autodiff_8cpp_source_l00033}\hyperlink{struct_test_func1}{00033} \textcolor{keyword}{struct }\hyperlink{struct_test_func1}{TestFunc1}
00034 \{
00035   \textcolor{keyword}{typedef} \_Scalar Scalar;
00036   \textcolor{keyword}{enum} \{
00037     InputsAtCompileTime = NX,
00038     ValuesAtCompileTime = NY
00039   \};
00040   \textcolor{keyword}{typedef} Matrix<Scalar,InputsAtCompileTime,1> InputType;
00041   \textcolor{keyword}{typedef} Matrix<Scalar,ValuesAtCompileTime,1> ValueType;
00042   \textcolor{keyword}{typedef} Matrix<Scalar,ValuesAtCompileTime,InputsAtCompileTime> JacobianType;
00043 
00044   \textcolor{keywordtype}{int} m\_inputs, m\_values;
00045 
00046   \hyperlink{struct_test_func1}{TestFunc1}() : m\_inputs(InputsAtCompileTime), m\_values(ValuesAtCompileTime) \{\}
00047   \hyperlink{struct_test_func1}{TestFunc1}(\textcolor{keywordtype}{int} inputs, \textcolor{keywordtype}{int} values) : m\_inputs(inputs), m\_values(values) \{\}
00048 
00049   \textcolor{keywordtype}{int} inputs()\textcolor{keyword}{ const }\{ \textcolor{keywordflow}{return} m\_inputs; \}
00050   \textcolor{keywordtype}{int} values()\textcolor{keyword}{ const }\{ \textcolor{keywordflow}{return} m\_values; \}
00051 
00052   \textcolor{keyword}{template}<\textcolor{keyword}{typename} T>
00053   \textcolor{keywordtype}{void} operator() (\textcolor{keyword}{const} Matrix<T,InputsAtCompileTime,1>& x, Matrix<T,ValuesAtCompileTime,1>* \_v)\textcolor{keyword}{ const}
00054 \textcolor{keyword}{  }\{
00055     Matrix<T,ValuesAtCompileTime,1>& v = *\_v;
00056 
00057     v[0] = 2 * x[0] * x[0] + x[0] * x[1];
00058     v[1] = 3 * x[1] * x[0] + 0.5 * x[1] * x[1];
00059     \textcolor{keywordflow}{if}(inputs()>2)
00060     \{
00061       v[0] += 0.5 * x[2];
00062       v[1] += x[2];
00063     \}
00064     \textcolor{keywordflow}{if}(values()>2)
00065     \{
00066       v[2] = 3 * x[1] * x[0] * x[0];
00067     \}
00068     \textcolor{keywordflow}{if} (inputs()>2 && values()>2)
00069       v[2] *= x[2];
00070   \}
00071 
00072   \textcolor{keywordtype}{void} operator() (\textcolor{keyword}{const} InputType& x, ValueType* v, JacobianType* \_j)\textcolor{keyword}{ const}
00073 \textcolor{keyword}{  }\{
00074     (*this)(x, v);
00075 
00076     \textcolor{keywordflow}{if}(\_j)
00077     \{
00078       JacobianType& j = *\_j;
00079 
00080       j(0,0) = 4 * x[0] + x[1];
00081       j(1,0) = 3 * x[1];
00082 
00083       j(0,1) = x[0];
00084       j(1,1) = 3 * x[0] + 2 * 0.5 * x[1];
00085 
00086       \textcolor{keywordflow}{if} (inputs()>2)
00087       \{
00088         j(0,2) = 0.5;
00089         j(1,2) = 1;
00090       \}
00091       \textcolor{keywordflow}{if}(values()>2)
00092       \{
00093         j(2,0) = 3 * x[1] * 2 * x[0];
00094         j(2,1) = 3 * x[0] * x[0];
00095       \}
00096       \textcolor{keywordflow}{if} (inputs()>2 && values()>2)
00097       \{
00098         j(2,0) *= x[2];
00099         j(2,1) *= x[2];
00100 
00101         j(2,2) = 3 * x[1] * x[0] * x[0];
00102         j(2,2) = 3 * x[1] * x[0] * x[0];
00103       \}
00104     \}
00105   \}
00106 \};
00107 
00108 
00109 \textcolor{preprocessor}{#if EIGEN\_HAS\_VARIADIC\_TEMPLATES}
00110 \textcolor{comment}{/* Test functor for the C++11 features. */}
00111 \textcolor{keyword}{template} <\textcolor{keyword}{typename} Scalar>
00112 \textcolor{keyword}{struct }integratorFunctor
00113 \{
00114     \textcolor{keyword}{typedef} Matrix<Scalar, 2, 1> InputType;
00115     \textcolor{keyword}{typedef} Matrix<Scalar, 2, 1> ValueType;
00116 
00117     \textcolor{comment}{/*}
00118 \textcolor{comment}{     * Implementation starts here.}
00119 \textcolor{comment}{     */}
00120     integratorFunctor(\textcolor{keyword}{const} Scalar gain) : \_gain(gain) \{\}
00121     integratorFunctor(\textcolor{keyword}{const} integratorFunctor& f) : \_gain(f.\_gain) \{\}
00122     \textcolor{keyword}{const} Scalar \_gain;
00123 
00124     \textcolor{keyword}{template} <\textcolor{keyword}{typename} T1, \textcolor{keyword}{typename} T2>
00125     \textcolor{keywordtype}{void} operator() (\textcolor{keyword}{const} T1 &input, T2 *output, \textcolor{keyword}{const} Scalar dt)\textcolor{keyword}{ const}
00126 \textcolor{keyword}{    }\{
00127         T2 &o = *output;
00128 
00129         \textcolor{comment}{/* Integrator to test the AD. */}
00130         o[0] = input[0] + input[1] * dt * \_gain;
00131         o[1] = input[1] * \_gain;
00132     \}
00133 
00134     \textcolor{comment}{/* Only needed for the test */}
00135     \textcolor{keyword}{template} <\textcolor{keyword}{typename} T1, \textcolor{keyword}{typename} T2, \textcolor{keyword}{typename} T3>
00136     \textcolor{keywordtype}{void} operator() (\textcolor{keyword}{const} T1 &input, T2 *output, T3 *jacobian, \textcolor{keyword}{const} Scalar dt)\textcolor{keyword}{ const}
00137 \textcolor{keyword}{    }\{
00138         T2 &o = *output;
00139 
00140         \textcolor{comment}{/* Integrator to test the AD. */}
00141         o[0] = input[0] + input[1] * dt * \_gain;
00142         o[1] = input[1] * \_gain;
00143 
00144         \textcolor{keywordflow}{if} (jacobian)
00145         \{
00146             T3 &j = *jacobian;
00147 
00148             j(0, 0) = 1;
00149             j(0, 1) = dt * \_gain;
00150             j(1, 0) = 0;
00151             j(1, 1) = \_gain;
00152         \}
00153     \}
00154 
00155 \};
00156 
00157 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Func> \textcolor{keywordtype}{void} forward\_jacobian\_cpp11(\textcolor{keyword}{const} Func& f)
00158 \{
00159     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Func::ValueType::Scalar Scalar;
00160     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Func::ValueType ValueType;
00161     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} Func::InputType InputType;
00162     \textcolor{keyword}{typedef} \textcolor{keyword}{typename} AutoDiffJacobian<Func>::JacobianType JacobianType;
00163 
00164     InputType x = InputType::Random(InputType::RowsAtCompileTime);
00165     ValueType y, yref;
00166     JacobianType j, jref;
00167 
00168     \textcolor{keyword}{const} Scalar dt = internal::random<double>();
00169 
00170     jref.setZero();
00171     yref.setZero();
00172     f(x, &yref, &jref, dt);
00173 
00174     \textcolor{comment}{//std::cerr << "y, yref, jref: " << "\(\backslash\)n";}
00175     \textcolor{comment}{//std::cerr << y.transpose() << "\(\backslash\)n\(\backslash\)n";}
00176     \textcolor{comment}{//std::cerr << yref << "\(\backslash\)n\(\backslash\)n";}
00177     \textcolor{comment}{//std::cerr << jref << "\(\backslash\)n\(\backslash\)n";}
00178 
00179     AutoDiffJacobian<Func> autoj(f);
00180     autoj(x, &y, &j, dt);
00181 
00182     \textcolor{comment}{//std::cerr << "y j (via autodiff): " << "\(\backslash\)n";}
00183     \textcolor{comment}{//std::cerr << y.transpose() << "\(\backslash\)n\(\backslash\)n";}
00184     \textcolor{comment}{//std::cerr << j << "\(\backslash\)n\(\backslash\)n";}
00185 
00186     VERIFY\_IS\_APPROX(y, yref);
00187     VERIFY\_IS\_APPROX(j, jref);
00188 \}
00189 \textcolor{preprocessor}{#endif}
00190 
00191 \textcolor{keyword}{template}<\textcolor{keyword}{typename} Func> \textcolor{keywordtype}{void} forward\_jacobian(\textcolor{keyword}{const} Func& f)
00192 \{
00193     \textcolor{keyword}{typename} Func::InputType x = Func::InputType::Random(f.inputs());
00194     \textcolor{keyword}{typename} Func::ValueType y(f.values()), yref(f.values());
00195     \textcolor{keyword}{typename} Func::JacobianType j(f.values(),f.inputs()), jref(f.values(),f.inputs());
00196 
00197     jref.setZero();
00198     yref.setZero();
00199     f(x,&yref,&jref);
00200 \textcolor{comment}{//     std::cerr << y.transpose() << "\(\backslash\)n\(\backslash\)n";;}
00201 \textcolor{comment}{//     std::cerr << j << "\(\backslash\)n\(\backslash\)n";;}
00202 
00203     j.setZero();
00204     y.setZero();
00205     AutoDiffJacobian<Func> autoj(f);
00206     autoj(x, &y, &j);
00207 \textcolor{comment}{//     std::cerr << y.transpose() << "\(\backslash\)n\(\backslash\)n";;}
00208 \textcolor{comment}{//     std::cerr << j << "\(\backslash\)n\(\backslash\)n";;}
00209 
00210     VERIFY\_IS\_APPROX(y, yref);
00211     VERIFY\_IS\_APPROX(j, jref);
00212 \}
00213 
00214 \textcolor{comment}{// TODO also check actual derivatives!}
00215 \textcolor{keyword}{template} <\textcolor{keywordtype}{int}>
00216 \textcolor{keywordtype}{void} test\_autodiff\_scalar()
00217 \{
00218   Vector2f p = Vector2f::Random();
00219   \textcolor{keyword}{typedef} AutoDiffScalar<Vector2f> AD;
00220   AD ax(p.x(),Vector2f::UnitX());
00221   AD ay(p.y(),Vector2f::UnitY());
00222   AD res = foo<AD>(ax,ay);
00223   VERIFY\_IS\_APPROX(res.value(), foo(p.x(),p.y()));
00224 \}
00225 
00226 
00227 \textcolor{comment}{// TODO also check actual derivatives!}
00228 \textcolor{keyword}{template} <\textcolor{keywordtype}{int}>
00229 \textcolor{keywordtype}{void} test\_autodiff\_vector()
00230 \{
00231   Vector2f p = Vector2f::Random();
00232   \textcolor{keyword}{typedef} AutoDiffScalar<Vector2f> AD;
00233   \textcolor{keyword}{typedef} Matrix<AD,2,1> VectorAD;
00234   VectorAD ap = p.cast<AD>();
00235   ap.x().derivatives() = Vector2f::UnitX();
00236   ap.y().derivatives() = Vector2f::UnitY();
00237 
00238   AD res = foo<VectorAD>(ap);
00239   VERIFY\_IS\_APPROX(res.value(), foo(p));
00240 \}
00241 
00242 \textcolor{keyword}{template} <\textcolor{keywordtype}{int}>
00243 \textcolor{keywordtype}{void} test\_autodiff\_jacobian()
00244 \{
00245   CALL\_SUBTEST(( forward\_jacobian(\hyperlink{struct_test_func1}{TestFunc1<double,2,2>}()) ));
00246   CALL\_SUBTEST(( forward\_jacobian(\hyperlink{struct_test_func1}{TestFunc1<double,2,3>}()) ));
00247   CALL\_SUBTEST(( forward\_jacobian(\hyperlink{struct_test_func1}{TestFunc1<double,3,2>}()) ));
00248   CALL\_SUBTEST(( forward\_jacobian(\hyperlink{struct_test_func1}{TestFunc1<double,3,3>}()) ));
00249   CALL\_SUBTEST(( forward\_jacobian(\hyperlink{struct_test_func1}{TestFunc1<double>}(3,3)) ));
00250 \textcolor{preprocessor}{#if EIGEN\_HAS\_VARIADIC\_TEMPLATES}
00251   CALL\_SUBTEST(( forward\_jacobian\_cpp11(integratorFunctor<double>(10)) ));
00252 \textcolor{preprocessor}{#endif}
00253 \}
00254 
00255 
00256 \textcolor{keyword}{template} <\textcolor{keywordtype}{int}>
00257 \textcolor{keywordtype}{void} test\_autodiff\_hessian()
00258 \{
00259   \textcolor{keyword}{typedef} AutoDiffScalar<VectorXd> AD;
00260   \textcolor{keyword}{typedef} Matrix<AD,Eigen::Dynamic,1> VectorAD;
00261   \textcolor{keyword}{typedef} AutoDiffScalar<VectorAD> ADD;
00262   \textcolor{keyword}{typedef} Matrix<ADD,Eigen::Dynamic,1> VectorADD;
00263   VectorADD x(2);
00264   \textcolor{keywordtype}{double} s1 = internal::random<double>(), s2 = internal::random<double>(), s3 = internal::random<double>(),
       s4 = internal::random<double>();
00265   x(0).value()=s1;
00266   x(1).value()=s2;
00267 
00268   \textcolor{comment}{//set unit vectors for the derivative directions (partial derivatives of the input vector)}
00269   x(0).derivatives().resize(2);
00270   x(0).derivatives().setZero();
00271   x(0).derivatives()(0)= 1;
00272   x(1).derivatives().resize(2);
00273   x(1).derivatives().setZero();
00274   x(1).derivatives()(1)=1;
00275 
00276   \textcolor{comment}{//repeat partial derivatives for the inner AutoDiffScalar}
00277   x(0).value().derivatives() = VectorXd::Unit(2,0);
00278   x(1).value().derivatives() = VectorXd::Unit(2,1);
00279 
00280   \textcolor{comment}{//set the hessian matrix to zero}
00281   \textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} idx=0; idx<2; idx++) \{
00282       x(0).derivatives()(idx).derivatives()  = VectorXd::Zero(2);
00283       x(1).derivatives()(idx).derivatives()  = VectorXd::Zero(2);
00284   \}
00285 
00286   ADD y = sin(AD(s3)*x(0) + AD(s4)*x(1));
00287 
00288   VERIFY\_IS\_APPROX(y.value().derivatives()(0), y.derivatives()(0).value());
00289   VERIFY\_IS\_APPROX(y.value().derivatives()(1), y.derivatives()(1).value());
00290   VERIFY\_IS\_APPROX(y.value().derivatives()(0), s3*std::cos(s1*s3+s2*s4));
00291   VERIFY\_IS\_APPROX(y.value().derivatives()(1), s4*std::cos(s1*s3+s2*s4));
00292   VERIFY\_IS\_APPROX(y.derivatives()(0).derivatives(), -std::sin(s1*s3+s2*s4)*Vector2d(s3*s3,s4*s3));
00293   VERIFY\_IS\_APPROX(y.derivatives()(1).derivatives(),  -std::sin(s1*s3+s2*s4)*Vector2d(s3*s4,s4*s4));
00294 
00295   ADD z = x(0)*x(1);
00296   VERIFY\_IS\_APPROX(z.derivatives()(0).derivatives(), Vector2d(0,1));
00297   VERIFY\_IS\_APPROX(z.derivatives()(1).derivatives(), Vector2d(1,0));
00298 \}
00299 
00300 \textcolor{keywordtype}{double} bug\_1222() \{
00301   \textcolor{keyword}{typedef} \hyperlink{class_eigen_1_1_auto_diff_scalar}{Eigen::AutoDiffScalar<Eigen::Vector3d>} AD;
00302   \textcolor{keyword}{const} \textcolor{keywordtype}{double} \_cv1\_3 = 1.0;
00303   \textcolor{keyword}{const} AD chi\_3 = 1.0;
00304   \textcolor{comment}{// this line did not work, because operator+ returns ADS<DerType&>, which then cannot be converted to
       ADS<DerType>}
00305   \textcolor{keyword}{const} AD denom = chi\_3 + \_cv1\_3;
00306   \textcolor{keywordflow}{return} denom.value();
00307 \}
00308 
00309 \textcolor{keywordtype}{double} bug\_1223() \{
00310   \textcolor{keyword}{using} std::min;
00311   \textcolor{keyword}{typedef} \hyperlink{class_eigen_1_1_auto_diff_scalar}{Eigen::AutoDiffScalar<Eigen::Vector3d>} AD;
00312 
00313   \textcolor{keyword}{const} \textcolor{keywordtype}{double} \_cv1\_3 = 1.0;
00314   \textcolor{keyword}{const} AD chi\_3 = 1.0;
00315   \textcolor{keyword}{const} AD denom = 1.0;
00316 
00317   \textcolor{comment}{// failed because implementation of min attempts to construct ADS<DerType&> via constructor
       AutoDiffScalar(const Real& value)}
00318   \textcolor{comment}{// without initializing m\_derivatives (which is a reference in this case)}
00319 \textcolor{preprocessor}{  #define EIGEN\_TEST\_SPACE}
00320   \textcolor{keyword}{const} AD t = min EIGEN\_TEST\_SPACE (denom / chi\_3, 1.0);
00321 
00322   \textcolor{keyword}{const} AD t2 = min EIGEN\_TEST\_SPACE (denom / (chi\_3 * \_cv1\_3), 1.0);
00323 
00324   \textcolor{keywordflow}{return} t.value() + t2.value();
00325 \}
00326 
00327 \textcolor{comment}{// regression test for some compilation issues with specializations of ScalarBinaryOpTraits}
00328 \textcolor{keywordtype}{void} bug\_1260() \{
00329   Matrix4d \hyperlink{group___core___module_class_eigen_1_1_matrix}{A};
00330   Vector4d v;
00331   A*v;
00332 \}
00333 
00334 \textcolor{comment}{// check a compilation issue with numext::max}
00335 \textcolor{keywordtype}{double} bug\_1261() \{
00336   \textcolor{keyword}{typedef} AutoDiffScalar<Matrix2d> AD;
00337   \textcolor{keyword}{typedef} Matrix<AD,2,1> VectorAD;
00338 
00339   VectorAD v;
00340   \textcolor{keyword}{const} AD maxVal = v.maxCoeff();
00341   \textcolor{keyword}{const} AD minVal = v.minCoeff();
00342   \textcolor{keywordflow}{return} maxVal.value() + minVal.value();
00343 \}
00344 
00345 \textcolor{keywordtype}{double} bug\_1264() \{
00346   \textcolor{keyword}{typedef} AutoDiffScalar<Vector2d> AD;
00347   \textcolor{keyword}{const} AD s;
00348   \textcolor{keyword}{const} Matrix<AD, 3, 1> v1;
00349   \textcolor{keyword}{const} Matrix<AD, 3, 1> v2 = (s + 3.0) * v1;
00350   \textcolor{keywordflow}{return} v2(0).value();
00351 \}
00352 
00353 \textcolor{keywordtype}{void} test\_autodiff()
00354 \{
00355   \textcolor{keywordflow}{for}(\textcolor{keywordtype}{int} i = 0; i < g\_repeat; i++) \{
00356     CALL\_SUBTEST\_1( test\_autodiff\_scalar<1>() );
00357     CALL\_SUBTEST\_2( test\_autodiff\_vector<1>() );
00358     CALL\_SUBTEST\_3( test\_autodiff\_jacobian<1>() );
00359     CALL\_SUBTEST\_4( test\_autodiff\_hessian<1>() );
00360   \}
00361 
00362   bug\_1222();
00363   bug\_1223();
00364   bug\_1260();
00365   bug\_1261();
00366 \}
00367 
\end{DoxyCode}
